{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esco import LocalDB\n",
    "db = LocalDB()\n",
    "skills_labels = [\n",
    "        \"collaborate with engineers\",\n",
    "        \"deploy cloud resource\",\n",
    "        \"design cloud architecture\",\n",
    "        \"design cloud networks\",\n",
    "        \"plan migration to cloud\",\n",
    "        \"automate cloud tasks\",\n",
    "        \"coordinate engineering teams\",\n",
    "        \"design database in the cloud\",\n",
    "        \"design for organisational complexity\",\n",
    "        \"develop with cloud services\",\n",
    "        \"do cloud refactoring\",\n",
    "    ]\n",
    "skills = db.skills[db.skills.label.str.lower().isin(skills_labels)]\n",
    "labels  = [l for labels in skills.allLabel for l in labels]\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root(doc):\n",
    "    for prefix in (\"\", \"to \"):\n",
    "        doc = nlp(prefix + doc.text)\n",
    "        for token in doc:\n",
    "            if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
    "                return token\n",
    "    return None\n",
    "\n",
    "def find_obj(token):\n",
    "    for child in token.children:\n",
    "        if child.dep_ == \"prep\":\n",
    "            return find_obj(child)\n",
    "        if child.dep_ in (\"dobj\", \"pobj\", \"nsubj\"):\n",
    "            return child\n",
    "    return None\n",
    "\n",
    "def find_compound(token):\n",
    "    compounds = []\n",
    "    if token:\n",
    "        compounds.append(token.lemma_)\n",
    "        for child in token.children:\n",
    "            if child.dep_ == \"compound\":\n",
    "                compounds.append(child.lemma_)\n",
    "    return \" \".join(reversed(compounds))  # Combine compounds into a single string\n",
    "comp_list = []\n",
    "docs = nlp.pipe(labels)\n",
    "for doc in docs:\n",
    "    verb = None\n",
    "    for token in doc:\n",
    "        verb = find_root(doc)\n",
    "    if not verb:\n",
    "        print(\"****missing verb\", doc.text)\n",
    "        continue\n",
    "    obj = find_obj(verb)\n",
    "    compound_str = find_compound(obj)\n",
    "    comp_list.append(compound_str)\n",
    "    print(verb.lemma_, compound_str, f\"-{doc.text}-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funzione per estrarre competenze potenziali\n",
    "def extract_potential_skills(text):\n",
    "    doc = nlp(text)\n",
    "    chunks = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if chunk.root.dep_ in ['dobj', 'pobj'] and chunk.root.head.pos_ == 'VERB':\n",
    "            verb = chunk.root.head\n",
    "            start = verb.i\n",
    "            end = chunk.end\n",
    "            chunks.append(doc[start:end])\n",
    "    return chunks\n",
    "\n",
    "# Funzione per valutare la rilevanza di un chunk come competenza\n",
    "def evaluate_chunk_as_skill(chunk, known_skills):\n",
    "    chunk_text = chunk.text.lower()\n",
    "    for skill in known_skills:\n",
    "        if skill in chunk_text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "text = \"During my internship, I wrote code to integrate cloud services and cloud networks.\"\n",
    "\n",
    "potential_skills = extract_potential_skills(text)\n",
    "for chunk in potential_skills:\n",
    "    if evaluate_chunk_as_skill(chunk, comp_list):\n",
    "        print(f\"Potential skill identified: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Potential skill identified: wrote code\n",
    "Potential skill identified: integrate cloud services\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = [\n",
    "    \"I am an experienced IT professional with a strong background in cloud computing and software development. \",\n",
    "    \"I specialize in planning and executing cloud migrations, designing cloud architectures, and automating cloud tasks. \",\n",
    "    \"My skills include creating cloud network, managing cloud resource, and developing cloud applications. \",\n",
    "    \"I am also adept to designing cloud environments for large organizations, ensuring they are scalable and efficient.\"\n",
    "]\n",
    "for text in test_text:\n",
    "    potential_skills = extract_potential_skills(text)\n",
    "    for chunk in potential_skills:\n",
    "        if evaluate_chunk_as_skill(chunk, comp_list):\n",
    "            print(f\"Potential skill identified: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Potential skill identified: executing cloud migrations\n",
    "Potential skill identified: designing cloud architectures\n",
    "Potential skill identified: automating cloud tasks\n",
    "Potential skill identified: creating cloud network\n",
    "Potential skill identified: managing cloud resource\n",
    "Potential skill identified: developing cloud applications\n",
    "Potential skill identified: designing cloud environments\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
